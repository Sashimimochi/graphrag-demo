import os
import asyncio
import nest_asyncio
import streamlit as st
import streamlit.components.v1 as components
from dotenv import load_dotenv
from utils.graph_visualize import visualize_graphml, show_hierarchy_graph
from utils.rag import make_index, search
from utils.common import select_dataset, select_language, select_graph_storage, check_storage, select_search_mode

nest_asyncio.apply()

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# Streamlitã®ãƒšãƒ¼ã‚¸è¨­å®š
def configure_page():
    st.set_page_config(
        page_title="GraphRAG Demo",
        page_icon="ğŸ§Š",
        layout="wide",
        initial_sidebar_state="expanded",
        menu_items={
            'Get Help': 'https://docs.streamlit.io/',
            'Report a bug': "https://docs.streamlit.io/",
            'About': "# This is a header. This is an *extremely* cool app!"
        }
    )

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
def initialize_session_state():
    if "conversation" not in st.session_state:
        st.session_state.conversation = []
    if "language" not in st.session_state:
        st.session_state.language = ""
    if "working_dir" not in st.session_state:
        st.session_state.working_dir = ""

# çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
def display_knowledge_graph(graph_storage, filename):
    if graph_storage == "Neo4JStorage":
        st.markdown(f"""
            <a href="{os.getenv("NEO4J_BROWSER_URI")}" target="_blank">
                Neo4j
            </a>
        """, unsafe_allow_html=True)
    else:
        filepath = f"./visualize/knowledge_graph_{filename}.html"
        if not os.path.exists(filepath):
            visualize_graphml(filename, filepath)
        with open(filepath, "r") as f:
            components.html(f.read(), height=500)
        df = show_hierarchy_graph(filename)
        st.dataframe(df)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
def initialize_chat_history():
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ç§ã¯ãŠåŠ©ã‘Botã§ã™ã€‚ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Œã°èã„ã¦ãã ã•ã„ã€‚"
            }
        ]

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
def display_chat_history():
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«åå¿œ
def handle_user_input(mode):
    if prompt := st.chat_input("LLMã¸ã®è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ex.ã“ã®æ–‡ç« ã®ä¸»è¦ãªãƒ†ãƒ¼ãƒã¯ãªã‚“ã§ã™ã‹ï¼Ÿ", key="query"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        st.chat_message("user").markdown(prompt)
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": prompt})
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        with st.chat_message("assistant"):
            with st.spinner("Assistant is thinking..."):
                placeholder = st.empty()
                msg = asyncio.run(search(mode, query=prompt))
                placeholder.markdown(msg)
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({"role": "assistant", "content": msg})

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å®šç¾©
async def main():
    configure_page()
    initialize_session_state()

    st.title("GraphRAG Demo")
    st.write("GraphRAGã®å¨åŠ›ã‚’ä½“æ„Ÿã§ãã‚‹ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã§ã™ã€‚")

    DATASET = select_dataset()
    st.session_state.working_dir = DATASET
    filename = DATASET
    if not st.session_state.working_dir:
        return

    st.session_state.language = select_language()

    graph_storage = select_graph_storage()
    check_storage(st.session_state.working_dir, filename)

    mode = select_search_mode()

    if st.button("Create Index", help="åˆã‚ã¦ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ã€è³ªå•ã®å‰ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"):
        with st.spinner("Creating index..."):
            await make_index(filename)
    if st.button("View Knowledge Graph", help="çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ç¢ºèªã™ã‚‹"):
        display_knowledge_graph(graph_storage, filename)

    initialize_chat_history()
    display_chat_history()
    handle_user_input(mode)

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(main())
